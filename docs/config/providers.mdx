---
title: Providers
description: Configure API keys and settings for AI providers
---

mux supports multiple AI providers. The easiest way to configure them is through **Settings → Providers** (`Cmd+,` / `Ctrl+,`).

## Quick Setup

1. Open Settings (`Cmd+,` / `Ctrl+,`)
2. Navigate to **Providers**
3. Expand any provider and enter your API key
4. Start using models from that provider

Most providers only need an API key. The UI handles validation and shows which providers are configured.

## Supported Providers

| Provider       | Models                     | Get API Key                                             |
| -------------- | -------------------------- | ------------------------------------------------------- |
| **Anthropic**  | Claude Opus, Sonnet, Haiku | [console.anthropic.com](https://console.anthropic.com/) |
| **OpenAI**     | GPT-5, Codex               | [platform.openai.com](https://platform.openai.com/)     |
| **Google**     | Gemini Pro, Flash          | [aistudio.google.com](https://aistudio.google.com/)     |
| **xAI**        | Grok                       | [console.x.ai](https://console.x.ai/)                   |
| **DeepSeek**   | DeepSeek Chat, Reasoner    | [platform.deepseek.com](https://platform.deepseek.com/) |
| **OpenRouter** | 300+ models                | [openrouter.ai](https://openrouter.ai/)                 |
| **Ollama**     | Local models               | [ollama.com](https://ollama.com/) (no key needed)       |
| **Bedrock**    | Claude via AWS             | AWS Console                                             |

## Environment Variables

Providers also read from environment variables as fallback:

| Provider   | Environment Variable                                       |
| ---------- | ---------------------------------------------------------- |
| Anthropic  | `ANTHROPIC_API_KEY` or `ANTHROPIC_AUTH_TOKEN`              |
| OpenAI     | `OPENAI_API_KEY`                                           |
| Google     | `GOOGLE_GENERATIVE_AI_API_KEY`                             |
| xAI        | `XAI_API_KEY`                                              |
| DeepSeek   | `DEEPSEEK_API_KEY`                                         |
| OpenRouter | `OPENROUTER_API_KEY`                                       |
| Bedrock    | `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION` |

## Advanced: Manual Configuration

For advanced options not exposed in the UI, edit `~/.mux/providers.jsonc` directly:

```jsonc
{
  "anthropic": {
    "apiKey": "sk-ant-...",
    "baseUrl": "https://api.anthropic.com", // Optional custom endpoint
  },
  "openrouter": {
    "apiKey": "sk-or-v1-...",
    // Provider routing preferences
    "order": ["Cerebras", "Fireworks"],
    "allow_fallbacks": true,
  },
  "xai": {
    "apiKey": "sk-xai-...",
    // Search orchestration settings
    "searchParameters": { "mode": "auto" },
  },
  "bedrock": {
    "region": "us-east-1",
    // Uses AWS credential chain if no explicit credentials
  },
  "ollama": {
    "baseUrl": "http://your-server:11434/api", // Custom Ollama server
  },
}
```

### Bedrock Authentication

Bedrock supports multiple authentication methods (tried in order):

1. **Bearer Token** — Single API key via `bearerToken` config or `AWS_BEARER_TOKEN_BEDROCK` env var
2. **Explicit Credentials** — `accessKeyId` + `secretAccessKey` in config
3. **AWS Credential Chain** — Automatic resolution from environment, `~/.aws/credentials`, SSO, EC2/ECS roles

If you're already authenticated with AWS CLI (`aws sso login`), mux uses those credentials automatically.

### OpenRouter Provider Routing

Control which infrastructure providers handle your requests:

- `order`: Priority list of providers (e.g., `["Cerebras", "Fireworks"]`)
- `allow_fallbacks`: Whether to try other providers if preferred ones are unavailable
- `only` / `ignore`: Restrict or exclude specific providers
- `data_collection`: `"allow"` or `"deny"` for training data policies

See [OpenRouter Provider Routing docs](https://openrouter.ai/docs/features/provider-routing) for details.

### xAI Search Orchestration

Grok models support live web search. mux enables this by default with `mode: "auto"`. Customize via [`searchParameters`](https://docs.x.ai/docs/resources/search) for regional focus, time filters, or to disable search.
