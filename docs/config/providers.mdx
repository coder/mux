---
title: Providers
description: Configure API keys and settings for AI providers
---

Mux supports multiple AI providers. The easiest way to configure them is through **Settings → Providers** (`Cmd+,` / `Ctrl+,`).

## Quick Setup

1. Open Settings (`Cmd+,` / `Ctrl+,`)
2. Navigate to **Providers**
3. Expand any provider and enter your API key
4. Start using models from that provider

Most providers only need an API key. The UI handles validation and shows which providers are configured.

## Supported Providers

| Provider           | Models                      | Get API Key                                             |
| ------------------ | --------------------------- | ------------------------------------------------------- |
| **Anthropic**      | Claude Opus, Sonnet, Haiku  | [console.anthropic.com](https://console.anthropic.com/) |
| **OpenAI**         | GPT-5, Codex                | [platform.openai.com](https://platform.openai.com/)     |
| **Google**         | Gemini Pro, Flash           | [aistudio.google.com](https://aistudio.google.com/)     |
| **xAI**            | Grok                        | [console.x.ai](https://console.x.ai/)                   |
| **DeepSeek**       | DeepSeek Chat, Reasoner     | [platform.deepseek.com](https://platform.deepseek.com/) |
| **OpenRouter**     | 300+ models                 | [openrouter.ai](https://openrouter.ai/)                 |
| **Ollama**         | Local models                | [ollama.com](https://ollama.com/) (no key needed)       |
| **Bedrock**        | Claude via AWS              | AWS Console                                             |
| **GitHub Copilot** | GPT-4o, Claude Sonnet, etc. | [GitHub Copilot](https://github.com/features/copilot)   |

## Environment Variables

Providers also read from environment variables as fallback:

{/* BEGIN PROVIDER_ENV_VARS */}

| Provider       | Environment Variable                               |
| -------------- | -------------------------------------------------- |
| Anthropic      | `ANTHROPIC_API_KEY` or `ANTHROPIC_AUTH_TOKEN`      |
| OpenAI         | `OPENAI_API_KEY`                                   |
| Google         | `GOOGLE_GENERATIVE_AI_API_KEY` or `GOOGLE_API_KEY` |
| xAI            | `XAI_API_KEY`                                      |
| OpenRouter     | `OPENROUTER_API_KEY`                               |
| DeepSeek       | `DEEPSEEK_API_KEY`                                 |
| github-copilot | `GITHUB_COPILOT_TOKEN`                             |
| Bedrock        | `AWS_REGION` (credentials via AWS SDK chain)       |

<details>
<summary>Additional environment variables</summary>

| Provider     | Variable                   | Purpose                      |
| ------------ | -------------------------- | ---------------------------- |
| Anthropic    | `ANTHROPIC_BASE_URL`       | Custom API endpoint          |
| OpenAI       | `OPENAI_BASE_URL`          | Custom API endpoint          |
| OpenAI       | `OPENAI_ORG_ID`            | Organization ID              |
| OpenAI       | `OPENAI_AUTH_MODE`         | Auth mode (`apiKey`/`entra`) |
| Google       | `GOOGLE_BASE_URL`          | Custom API endpoint          |
| xAI          | `XAI_BASE_URL`             | Custom API endpoint          |
| Azure OpenAI | `AZURE_OPENAI_API_KEY`     | API key                      |
| Azure OpenAI | `AZURE_OPENAI_ENDPOINT`    | Endpoint URL                 |
| Azure OpenAI | `AZURE_OPENAI_DEPLOYMENT`  | Deployment name              |
| Azure OpenAI | `AZURE_OPENAI_API_VERSION` | API version                  |

Azure OpenAI env vars configure the OpenAI provider with Azure backend.

</details>

{/* END PROVIDER_ENV_VARS */}

## Advanced: Manual Configuration

For advanced options not exposed in the UI, edit `~/.mux/providers.jsonc` directly:

```jsonc
{
  "anthropic": {
    "apiKey": "sk-ant-...",
    "baseUrl": "https://api.anthropic.com", // Optional custom endpoint
  },
  "openrouter": {
    "apiKey": "sk-or-v1-...",
    // Provider routing preferences
    "order": ["Cerebras", "Fireworks"],
    "allow_fallbacks": true,
  },
  "xai": {
    "apiKey": "sk-xai-...",
    // Search orchestration settings
    "searchParameters": { "mode": "auto" },
  },
  "bedrock": {
    "region": "us-east-1",
    // Uses AWS credential chain if no explicit credentials
  },
  "ollama": {
    "baseUrl": "http://your-server:11434/api", // Custom Ollama server
  },
}
```

### OpenAI: Azure Entra ID (Keyless)

Use Azure Entra ID credentials instead of API keys when routing the OpenAI provider through an Azure OpenAI endpoint.

**Required configuration**

- Set `OPENAI_AUTH_MODE=entra` (or `"authMode": "entra"` under `"openai"` in `~/.mux/providers.jsonc`).
- Set `OPENAI_BASE_URL` to your Azure OpenAI endpoint (for example `https://my-resource.openai.azure.com`).
- Do not set `OPENAI_API_KEY` for this mode.

**How it works**

Mux uses `DefaultAzureCredential` from `@azure/identity`, which supports:

- Local development with `az login`
- CI/CD with managed identity or workload identity

**OpenAI auth priority**

1. API key (if set)
2. Codex OAuth (if applicable)
3. Entra keyless (`authMode: "entra"` + Azure `baseUrl`)
4. Error if no auth path is configured

**`providers.jsonc` example**

```jsonc
{
  "openai": {
    "authMode": "entra",
    "baseUrl": "https://my-resource.openai.azure.com",
  },
}
```

**Environment-only example**

```sh
OPENAI_AUTH_MODE=entra
OPENAI_BASE_URL=https://my-resource.openai.azure.com
```

### Bedrock Authentication

Bedrock supports multiple authentication methods (tried in order):

1. **Bearer Token** — Single API key via `bearerToken` config or `AWS_BEARER_TOKEN_BEDROCK` env var
2. **Explicit Credentials** — `accessKeyId` + `secretAccessKey` in config
3. **AWS Credential Chain** — Automatic resolution from environment, `~/.aws/credentials`, SSO, EC2/ECS roles

If you're already authenticated with AWS CLI (`aws sso login`), Mux uses those credentials automatically.

### OpenRouter Provider Routing

Control which infrastructure providers handle your requests:

- `order`: Priority list of providers (e.g., `["Cerebras", "Fireworks"]`)
- `allow_fallbacks`: Whether to try other providers if preferred ones are unavailable
- `only` / `ignore`: Restrict or exclude specific providers
- `data_collection`: `"allow"` or `"deny"` for training data policies

See [OpenRouter Provider Routing docs](https://openrouter.ai/docs/features/provider-routing) for details.

### xAI Search Orchestration

Grok models support live web search. Mux enables this by default with `mode: "auto"`. Customize via [`searchParameters`](https://docs.x.ai/docs/resources/search) for regional focus, time filters, or to disable search.
